---
layout: page
title: Samin Yeasar Arnob
subtitle: 
---

I am a visiting student-researcher at **Microsoft Research, Montreal** and doing a Ph.D. in Computer Science at **McGill University** and [Mila Quebec AI Institute][1] working with [Dr. Doina Precup][3].

My research focus is on "**Improving the Learning Capacity and Parameter Efficient training for RL and LLMs**". I am working on efficiently using neural networks where we take inspiration from the human brain, using multiple specialized pathways through a single network, with each pathway focusing on a single task. This is an alternate way to "routing" and a mixture of expert structures that can be added to LLM. 

I'm interested in the ***Mixture of experts*** (MoE), ***Parameter-efficient finetuning*** (peft) in LLM, ***Preference fine-tuning*** using Reinforcement Learning (RL), LLM ***alignment***, ***Improving mergability of a mixture of experts***.

---
Prior I did applied research internships at **Microsoft Research, New York** (summer 2023, host: John Lanford, Alex Lamb), **Ubisoft La Forge, Montreal** (2021-2022, host: Joshua Romoff), **Mila Quebec AI Institute** (2019, host: Doina Precup)

I completed Master's in Electrical and Computer Engineering at McGill University.  My master's research was on "Adversarial Inverse Reinforcement Learning" under the supervision of [Dr. Aditya Mahajan][4] at [Centre for Intelligent Machine (CIM)][5].


[1]:https://mila.quebec/
[2]:http://rl.cs.mcgill.ca/
[3]:https://www.linkedin.com/in/doina-precup-1ba61314/
[4]:http://www.ece.mcgill.ca/~amahaj1/
[5]:https://www.mcgill.ca/cim/

### Affiliations
<img src="https://imgur.com/IRBaiqh.png" width="120" height="50"> <img src="https://imgur.com/EQKabmk.png" width="120" height="65"> <img src="https://imgur.com/eWTBidl.png" width="60" height="55">
#### Previously
<img src="https://imgur.com/A8iS0di.png" width="60" height="55">
 
### News
* **September 2024.** "**Parameter-efficient Reinforcement Learning by Discovering Neural Pathways**" got accepted in **NeurIPS 2024**! ðŸŽ‰
* **March 2024.** I'm joining **Microsoft Research**, Montreal as part-time research intern. I will be working on Multitask and Multimodal learning using LLM.
* **May, 2023- Aug, 2023.** I worked at **Microsoft Research**, New York as **Research Intern**, on an Appiled RL project with John Langford and Alex Lamb.
* **October, 2021.** Two papers got accepted in **Offline Reinforcement Learning Workshop, NeurIPS 2021**
  - "Importance of Empirical Sample Complexity Analysis for Offline Reinforcement Learning" - [Paper](https://offline-rl-neurips.github.io/2021/pdf/38.pdf)
  - "Single-Shot Pruning for Offline Reinforcement Learning" - [Paper](https://offline-rl-neurips.github.io/2021/pdf/27.pdf)
* **Sep, 2021- Aug 2022.** I have worked at **Ubisoft**, Montreal with Joshua Romoff as **Research Intern**.
* **June, 2020.** "Off-Policy Adversarial Inverse Reinforcement Learning" got accepted in **Lifelong Learning workshop, ICML 2020**.
    [Paper](https://openreview.net/forum?id=9mp5d073IhX), [Code](https://github.com/SaminYeasar/Off_Policy_Adversarial_Inverse_Reinforcement_Learning),[Talk](https://www.youtube.com/watch?v=PK3byu61JKI&ab_channel=SaminYeasarArnob)
* **January, 2020.** I have started my **Ph.D.** at **McGill University**.
* **June, 2019.** I joined **Mila** as **Research Intern**.
* **June, 2019.** "Doubly Robust Estimators in Off-Policy Actor-Critic Algorithms" got accepted for **spotlight** presentation at **RLDM 2019**
* **January, 2018.** I started my Master's at McGill University.


### Research Interest

* Reinforcement Learning
* Imitation Learning
* Offline  Reinforcement Learning
* Representation learning
* Multitask Learning
* Generative Adversarial Networks 
* Hierarchical Reinforcement Learning
